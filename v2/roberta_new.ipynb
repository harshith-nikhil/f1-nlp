{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74875fc9-218d-4674-86e3-47f7b00b76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def flatten_squad(path):\n",
    "    raw = load_dataset(\"json\", data_files=path, field=\"data\")[\"train\"]\n",
    "    rows = []\n",
    "    for item in raw:\n",
    "        for p in item[\"paragraphs\"]:\n",
    "            ctx = p[\"context\"]\n",
    "            for qa in p[\"qas\"]:\n",
    "                rows.append({\n",
    "                    \"context\":      ctx,\n",
    "                    \"question\":     qa[\"question\"],\n",
    "                    \"answer_start\": qa[\"answers\"][0][\"answer_start\"],\n",
    "                    \"answer_text\":  qa[\"answers\"][0][\"text\"],\n",
    "                })\n",
    "    return Dataset.from_list(rows)\n",
    "\n",
    "train_ds = flatten_squad(\"f1_gp_qa_new.json\")\n",
    "val_ds   = flatten_squad(\"f1_gp_qa_val.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b990706-9db7-4adf-9799-eae5cd0f34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317423301439431585a1364c85628e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b9099b59ba4fbaa292ff1bce3c0ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Train examples: 124\n",
      "▶️ Val   examples: 124\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def prepare_features(examples):\n",
    "    # 1) Tokenize without overflowing\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",     # only chop the context\n",
    "        max_length=512,               # full capacity, no overflow\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True   # we need this to align spans\n",
    "    )\n",
    "\n",
    "    starts, ends = [], []\n",
    "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
    "        start_char = examples[\"answer_start\"][i]\n",
    "        end_char   = start_char + len(examples[\"answer_text\"][i])\n",
    "\n",
    "        # 2) Find token_start: first token whose span covers start_char\n",
    "        token_start = 0\n",
    "        while (\n",
    "            token_start < len(offsets) \n",
    "            and offsets[token_start][1] <= start_char\n",
    "        ):\n",
    "            token_start += 1\n",
    "\n",
    "        # 3) Find token_end: last token whose span covers end_char\n",
    "        token_end = len(offsets) - 1\n",
    "        while (\n",
    "            token_end >= 0 \n",
    "            and offsets[token_end][0] >= end_char\n",
    "        ):\n",
    "            token_end -= 1\n",
    "\n",
    "        # 4) Clamp into valid range\n",
    "        token_start = min(max(token_start, 0), len(offsets) - 1)\n",
    "        token_end   = min(max(token_end,   0), len(offsets) - 1)\n",
    "\n",
    "        starts.append(token_start)\n",
    "        ends.append(token_end)\n",
    "\n",
    "    tokenized[\"start_positions\"] = starts\n",
    "    tokenized[\"end_positions\"]   = ends\n",
    "    tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "    return tokenized\n",
    "train_tok = train_ds.map(\n",
    "    prepare_features, batched=True, remove_columns=train_ds.column_names\n",
    ")\n",
    "val_tok = val_ds.map(\n",
    "    prepare_features, batched=True, remove_columns=val_ds.column_names\n",
    ")\n",
    "print(f\"▶️ Train examples: {len(train_tok)}\")\n",
    "print(f\"▶️ Val   examples: {len(val_tok)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2f9a90-eaad-46b0-94f7-39dbbd71deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1971/1189929703.py:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='775' max='775' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [775/775 06:52, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.817150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.565747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.442571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.199984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.972858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.796567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.642395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.585462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.682444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.670906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.577517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.636831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.554955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.626333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.626530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.594349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.774943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.613355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.686391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.657825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.764224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.723440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.765576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.763288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.882700</td>\n",
       "      <td>1.772394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=775, training_loss=1.5853458527595765, metrics={'train_runtime': 413.152, 'train_samples_per_second': 7.503, 'train_steps_per_second': 1.876, 'total_flos': 810019945881600.0, 'train_loss': 1.5853458527595765, 'epoch': 25.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForQuestionAnswering\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"roberta-base\")\n",
    "args  = TrainingArguments(\n",
    "    output_dir=\"./rob-f1-qa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=25,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b0ab8bf-8172-45c1-ae4b-6ddefe3b172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(prediction: str, reference: str) -> float:\n",
    "    pred_tokens = prediction.split()\n",
    "    ref_tokens  = reference.split()\n",
    "    common = set(pred_tokens) & set(ref_tokens)\n",
    "    if not common:\n",
    "        return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall    = len(common) / len(ref_tokens)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# 2) Evaluate EM, F1 on val_ds\n",
    "def evaluate_on_val(trainer, val_ds):\n",
    "    qa_pipe = pipeline(\n",
    "        \"question-answering\",\n",
    "        model=trainer.model,\n",
    "        tokenizer=trainer.tokenizer,\n",
    "        device=-1  # or device=0 if you want GPU\n",
    "    )\n",
    "    em_scores, f1_scores = [], []\n",
    "    for ex in val_ds:\n",
    "        out   = qa_pipe({\"question\": ex[\"question\"], \"context\": ex[\"context\"]})\n",
    "        pred  = out[\"answer\"].strip()\n",
    "        truth = ex[\"answer_text\"].strip()\n",
    "        em    = 1.0 if pred == truth else 0.0\n",
    "        f1    = compute_f1(pred, truth)\n",
    "        em_scores.append(em)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    accuracy = sum(em_scores) / len(em_scores)\n",
    "    avg_f1    = sum(f1_scores) / len(f1_scores)\n",
    "    return accuracy, avg_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba11ec86-aa51-4a33-9c56-8fd41ec99959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fdf3c-ff67-4540-973d-08ed5b535ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Trial: lr=0.01, epochs=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1971/1352493596.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='187' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [187/620 01:06 < 02:35, 2.79 it/s, Epoch 6/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.327900</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.327900</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.442000</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.406400</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.406400</td>\n",
       "      <td>6.238326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [1e-2, 1e-3, 1e-4]\n",
    "epoch_list     = [20, 25, 30]\n",
    "batch_size     = 4\n",
    "\n",
    "best_loss = math.inf\n",
    "best_cfg  = None\n",
    "\n",
    "for lr, epochs in product(learning_rates, epoch_list):\n",
    "    print(f\"\\n▶ Trial: lr={lr}, epochs={epochs}\")\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./rob-lr{lr}-ep{epochs}\",\n",
    "        overwrite_output_dir=True,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=epochs,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        greater_is_better=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=lambda: AutoModelForQuestionAnswering.from_pretrained(\"roberta-base\"),\n",
    "        args=args,\n",
    "        train_dataset=train_tok,\n",
    "        eval_dataset=val_tok,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    val_loss = metrics[\"eval_loss\"]\n",
    "    accuracy, f1 = evaluate_on_val(trainer, val_ds)\n",
    "\n",
    "    print(f\"→ Val loss: {val_loss:.4f}  EM/Accuracy: {accuracy:.3f}  F1: {f1:.3f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_cfg  = {\"learning_rate\": lr, \"epochs\": epochs, \"EM\": accuracy, \"F1\": f1}\n",
    "\n",
    "print(\"\\nBest config:\", best_cfg, f\"with eval_loss={best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb473cc-f364-4a07-9dfd-5628128a50d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
