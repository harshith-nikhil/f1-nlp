{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74875fc9-218d-4674-86e3-47f7b00b76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "def flatten_squad(path):\n",
    "    raw = load_dataset(\"json\", data_files=path, field=\"data\")[\"train\"]\n",
    "    rows = []\n",
    "    for item in raw:\n",
    "        for p in item[\"paragraphs\"]:\n",
    "            ctx = p[\"context\"]\n",
    "            for qa in p[\"qas\"]:\n",
    "                rows.append({\n",
    "                    \"context\":      ctx,\n",
    "                    \"question\":     qa[\"question\"],\n",
    "                    \"answer_start\": qa[\"answers\"][0][\"answer_start\"],\n",
    "                    \"answer_text\":  qa[\"answers\"][0][\"text\"],\n",
    "                })\n",
    "    return Dataset.from_list(rows)\n",
    "\n",
    "train_ds = flatten_squad(\"f1_gp_qa_new.json\")\n",
    "val_ds   = flatten_squad(\"f1_gp_qa_val.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b990706-9db7-4adf-9799-eae5cd0f34d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae14e96b1503414f8f5a0a1cc7526334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d7dbedb66a4ffeab0f20bd8af25670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/124 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Train examples: 124\n",
      "▶️ Val   examples: 124\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    RobertaTokenizerFast,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n",
    "def prepare_features(examples):\n",
    "    # 1) Tokenize without overflowing\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        truncation=\"only_second\",     # only chop the context\n",
    "        max_length=512,               # full capacity, no overflow\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True   # we need this to align spans\n",
    "    )\n",
    "\n",
    "    starts, ends = [], []\n",
    "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
    "        start_char = examples[\"answer_start\"][i]\n",
    "        end_char   = start_char + len(examples[\"answer_text\"][i])\n",
    "\n",
    "        # 2) Find token_start: first token whose span covers start_char\n",
    "        token_start = 0\n",
    "        while (\n",
    "            token_start < len(offsets) \n",
    "            and offsets[token_start][1] <= start_char\n",
    "        ):\n",
    "            token_start += 1\n",
    "\n",
    "        # 3) Find token_end: last token whose span covers end_char\n",
    "        token_end = len(offsets) - 1\n",
    "        while (\n",
    "            token_end >= 0 \n",
    "            and offsets[token_end][0] >= end_char\n",
    "        ):\n",
    "            token_end -= 1\n",
    "\n",
    "        # 4) Clamp into valid range\n",
    "        token_start = min(max(token_start, 0), len(offsets) - 1)\n",
    "        token_end   = min(max(token_end,   0), len(offsets) - 1)\n",
    "\n",
    "        starts.append(token_start)\n",
    "        ends.append(token_end)\n",
    "\n",
    "    tokenized[\"start_positions\"] = starts\n",
    "    tokenized[\"end_positions\"]   = ends\n",
    "    tokenized.pop(\"offset_mapping\")\n",
    "\n",
    "    return tokenized\n",
    "train_tok = train_ds.map(\n",
    "    prepare_features, batched=True, remove_columns=train_ds.column_names\n",
    ")\n",
    "val_tok = val_ds.map(\n",
    "    prepare_features, batched=True, remove_columns=val_ds.column_names\n",
    ")\n",
    "print(f\"▶️ Train examples: {len(train_tok)}\")\n",
    "print(f\"▶️ Val   examples: {len(val_tok)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2fcaf-7bb6-4ec8-9155-b63a5a9e587a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cd14343-e473-4e39-84a0-f34975622867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from transformers import pipeline\n",
    "\n",
    "# 1) Load metrics\n",
    "bleu_metric  = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "chrf_metric  = evaluate.load(\"chrf\")\n",
    "\n",
    "qa_pipe = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=trainer.model,\n",
    "    tokenizer=trainer.tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def compute_metrics(_):\n",
    "    preds, refs = [], []\n",
    "    for ex in val_ds:\n",
    "        out  = qa_pipe({\"question\": ex[\"question\"], \"context\": ex[\"context\"]})\n",
    "        pred = out[\"answer\"].strip()\n",
    "        ref  = ex[\"answer_text\"].strip()\n",
    "        preds.append(pred)\n",
    "        refs.append(ref)\n",
    "\n",
    "    # BLEU: predictions=list[str], references=list[list[str]]\n",
    "    bleu = bleu_metric.compute(\n",
    "        predictions=preds,\n",
    "        references=[[r] for r in refs]\n",
    "    )[\"bleu\"]\n",
    "\n",
    "    # ROUGE: raw strings → returns dict of floats\n",
    "    rouge_scores = rouge_metric.compute(\n",
    "        predictions=preds,\n",
    "        references=refs,\n",
    "        use_stemmer=True\n",
    "    )\n",
    "    rouge_l = rouge_scores[\"rougeL\"]  # already a float\n",
    "\n",
    "    # chrF: raw strings\n",
    "    chrf = chrf_metric.compute(\n",
    "        predictions=preds,\n",
    "        references=refs\n",
    "    )[\"score\"]\n",
    "\n",
    "    return {\n",
    "        \"bleu\":   bleu,\n",
    "        \"rougeL\": rouge_l,\n",
    "        \"chrf\":   chrf,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af2f9a90-eaad-46b0-94f7-39dbbd71deaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_5888/1625736297.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "import torch\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"roberta-base\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-qa-model\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=30,\n",
    "    learning_rate=2e-4,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f04c1c8-0786-47e0-b027-1cdbc1d828ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/930 01:15 < 06:20, 2.03 it/s, Epoch 5/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Chrf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.379800</td>\n",
       "      <td>1.884452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.052000</td>\n",
       "      <td>2.286960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.895200</td>\n",
       "      <td>1.853586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.891100</td>\n",
       "      <td>2.158793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.093600</td>\n",
       "      <td>2.586417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=155, training_loss=2.6623558290543095, metrics={'train_runtime': 75.3409, 'train_samples_per_second': 49.376, 'train_steps_per_second': 12.344, 'total_flos': 162003989176320.0, 'train_loss': 2.6623558290543095, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62c37a99-f796-471d-826f-f0f0aa88040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'grad_norm', 'learning_rate', 'epoch', 'step', 'eval_loss', 'eval_bleu', 'eval_rougeL', 'eval_chrf', 'eval_runtime', 'eval_samples_per_second', 'eval_steps_per_second', 'train_runtime', 'train_samples_per_second', 'train_steps_per_second', 'total_flos', 'train_loss']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_bleu</th>\n",
       "      <th>val_rougeL</th>\n",
       "      <th>val_chrf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.884452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.286960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.853586</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.8911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.158793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.586417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>5.222055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  val_loss  val_bleu  val_rougeL  val_chrf\n",
       "0     1.0      3.3798       NaN       NaN         NaN       NaN\n",
       "1     1.0         NaN  1.884452       0.0    0.047485  5.222055\n",
       "2     2.0      2.0520       NaN       NaN         NaN       NaN\n",
       "3     2.0         NaN  2.286960       0.0    0.047485  5.222055\n",
       "4     3.0      1.8952       NaN       NaN         NaN       NaN\n",
       "5     3.0         NaN  1.853586       0.0    0.047485  5.222055\n",
       "6     4.0      3.8911       NaN       NaN         NaN       NaN\n",
       "7     4.0         NaN  2.158793       0.0    0.047485  5.222055\n",
       "8     5.0      2.0936       NaN       NaN         NaN       NaN\n",
       "9     5.0         NaN  2.586417       0.0    0.047485  5.222055\n",
       "10    5.0         NaN       NaN       NaN         NaN       NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Inspect what metrics actually landed in your log history\n",
    "logs = trainer.state.log_history\n",
    "df   = pd.DataFrame(logs)\n",
    "print(df.columns.tolist())  # look for 'eval_bleu', 'eval_rougeL', 'eval_chrf'\n",
    "\n",
    "# 2) Keep only epoch‐end rows\n",
    "df_epoch = df[df[\"epoch\"].notnull()]\n",
    "\n",
    "# 3) Select the correctly-named eval metrics\n",
    "metrics_df = df_epoch[[\n",
    "    \"epoch\",\n",
    "    \"loss\",          # training loss\n",
    "    \"eval_loss\",     # validation loss\n",
    "    \"eval_bleu\",     # BLEU score\n",
    "    \"eval_rougeL\",   # ROUGE-L score\n",
    "    \"eval_chrf\"      # chrF score\n",
    "]].rename(columns={\n",
    "    \"loss\":        \"train_loss\",\n",
    "    \"eval_loss\":   \"val_loss\",\n",
    "    \"eval_bleu\":   \"val_bleu\",\n",
    "    \"eval_rougeL\": \"val_rougeL\",\n",
    "    \"eval_chrf\":   \"val_chrf\",\n",
    "})\n",
    "\n",
    "# 4) Save & show\n",
    "metrics_df.to_csv(\"epoch_textsim_metrics.csv\", index=False)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5077e-077a-4f29-9684-e7eda0f00fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
