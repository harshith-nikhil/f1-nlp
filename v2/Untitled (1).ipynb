{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47015955-a626-42ce-9578-18128edfcb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3465 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded context length: 9555 chars]\n",
      "\n",
      "Question → 5 tokens\n",
      "Context  → 3465 tokens\n",
      "→ Generated 14 windows\n",
      "\n",
      "Window lengths: [384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384, 384]\n",
      "windows × length: torch.Size([14, 384])\n",
      "Window 0:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7573\n",
      "  Raw start_logits[:5] = [8.908, -8.746, -8.745, -8.765, -8.729]\n",
      "  Raw   end_logits[:5] = [8.849, -8.732, -8.73, -8.743, -8.71]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [25, 365, 6, 7074, 2]\n",
      "\n",
      "Window 1:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7523\n",
      "  Raw start_logits[:5] = [8.906, -8.738, -8.733, -8.731, -8.754]\n",
      "  Raw   end_logits[:5] = [8.846, -8.691, -8.695, -8.689, -8.705]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [17058, 35, 42960, 4, 2]\n",
      "\n",
      "Window 2:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7632\n",
      "  Raw start_logits[:5] = [8.913, -8.766, -8.766, -8.767, -8.757]\n",
      "  Raw   end_logits[:5] = [8.851, -8.733, -8.735, -8.738, -8.717]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [8858, 341, 5, 22718, 2]\n",
      "\n",
      "Window 3:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7596\n",
      "  Raw start_logits[:5] = [8.91, -8.708, -8.726, -8.756, -8.747]\n",
      "  Raw   end_logits[:5] = [8.85, -8.707, -8.732, -8.742, -8.73]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [13, 112, 8040, 1640, 2]\n",
      "\n",
      "Window 4:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7670\n",
      "  Raw start_logits[:5] = [8.913, -8.747, -8.751, -8.783, -8.755]\n",
      "  Raw   end_logits[:5] = [8.854, -8.736, -8.746, -8.762, -8.726]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [29, 238, 19, 275, 2]\n",
      "\n",
      "Window 5:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7601\n",
      "  Raw start_logits[:5] = [8.912, -8.754, -8.752, -8.783, -8.757]\n",
      "  Raw   end_logits[:5] = [8.848, -8.751, -8.762, -8.767, -8.736]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [15, 14, 13406, 11, 2]\n",
      "\n",
      "Window 6:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7643\n",
      "  Raw start_logits[:5] = [8.912, -8.758, -8.767, -8.786, -8.764]\n",
      "  Raw   end_logits[:5] = [8.852, -8.772, -8.773, -8.779, -8.75]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [11, 9465, 35, 1360, 2]\n",
      "\n",
      "Window 7:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7548\n",
      "  Raw start_logits[:5] = [8.907, -8.751, -8.762, -8.781, -8.761]\n",
      "  Raw   end_logits[:5] = [8.848, -8.747, -8.757, -8.754, -8.735]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [5, 289, 11250, 13406, 2]\n",
      "\n",
      "Window 8:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7734\n",
      "  Raw start_logits[:5] = [8.924, -8.751, -8.758, -8.78, -8.762]\n",
      "  Raw   end_logits[:5] = [8.85, -8.774, -8.773, -8.776, -8.747]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [35, 3367, 4, 34322, 2]\n",
      "\n",
      "Window 9:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7659\n",
      "  Raw start_logits[:5] = [8.917, -8.775, -8.791, -8.807, -8.779]\n",
      "  Raw   end_logits[:5] = [8.849, -8.766, -8.751, -8.764, -8.735]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [844, 4, 40141, 4, 2]\n",
      "\n",
      "Window 10:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7672\n",
      "  Raw start_logits[:5] = [8.918, -8.778, -8.792, -8.801, -8.783]\n",
      "  Raw   end_logits[:5] = [8.849, -8.779, -8.764, -8.782, -8.763]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [289, 922, 6944, 2865, 2]\n",
      "\n",
      "Window 11:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7670\n",
      "  Raw start_logits[:5] = [8.915, -8.787, -8.8, -8.806, -8.787]\n",
      "  Raw   end_logits[:5] = [8.852, -8.787, -8.77, -8.789, -8.758]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [17, 27, 29, 1374, 2]\n",
      "\n",
      "Window 12:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.7216\n",
      "  Raw start_logits[:5] = [8.888, -8.781, -8.795, -8.793, -8.779]\n",
      "  Raw   end_logits[:5] = [8.834, -8.771, -8.759, -8.767, -8.74]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [927, 156, 646, 246, 2]\n",
      "\n",
      "Window 13:\n",
      "  CLS token id     = 0\n",
      "  Chosen start_idx = 0, end_idx = 0\n",
      "  Combined score   = 17.6667\n",
      "  Raw start_logits[:5] = [8.86, -8.72, -8.685, -8.659, -8.648]\n",
      "  Raw   end_logits[:5] = [8.806, -8.643, -8.623, -8.588, -8.589]\n",
      "  Offsets[0:5]         = [[0, 0], [0, 3], [4, 7], [8, 11], [12, 16]]\n",
      "  Token IDs [0:5]      = [0, 12375, 351, 5, 1015] ... [1, 1, 1, 1, 1]\n",
      "\n",
      "=== GLOBAL BEST SPAN ===\n",
      "Window 8, tokens [0, 0], score 17.7734\n",
      "Answer text: ''\n"
     ]
    }
   ],
   "source": [
    "# debug_qa_windows.py\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# 1) Local checkpoint + JSON paths\n",
    "CHECKPOINT    = \"qa_roberta_checkpoint\"    # your saved model folder\n",
    "ORIGINAL_JSON = \"train.json\"            # your original QA JSON\n",
    "\n",
    "# 2) Reload tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(CHECKPOINT, local_files_only=True)\n",
    "model     = AutoModelForQuestionAnswering.from_pretrained(CHECKPOINT, local_files_only=True)\n",
    "model.eval()\n",
    "\n",
    "# 3) Load & concatenate full context\n",
    "data = load_dataset(\"json\", data_files={\"full\": ORIGINAL_JSON}, field=\"data\")[\"full\"]\n",
    "record  = data[0]  # the race you trained on\n",
    "context = \"\\n\\n\".join(p[\"context\"] for p in record[\"paragraphs\"])\n",
    "print(f\"[Loaded context length: {len(context)} chars]\\n\")\n",
    "\n",
    "# 4) Question to debug\n",
    "question = \"Who won the race?\"\n",
    "q_tokens = tokenizer.tokenize(question)\n",
    "c_tokens = tokenizer.tokenize(context)\n",
    "print(f\"Question → {len(q_tokens)} tokens\")\n",
    "print(f\"Context  → {len(c_tokens)} tokens\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5) Tokenize into sliding windows (mirror training)\n",
    "enc = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=384,\n",
    "    truncation=\"only_second\",       # only cut the context to max_length\n",
    "    stride=128,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    padding=\"max_length\",              # pad all windows to same length\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "num_windows = enc.input_ids.size(0)\n",
    "print(f\"→ Generated {num_windows} windows\\n\")\n",
    "lens = [len(win) for win in enc[\"input_ids\"]]\n",
    "print(\"Window lengths:\", lens)\n",
    "print(\"windows × length:\", enc.input_ids.shape)\n",
    "# 6) Loop & debug\n",
    "best_score = -1e9\n",
    "best_span  = (None, None, None)  # (win_i, start_idx, end_idx)\n",
    "\n",
    "for win_i in range(num_windows):\n",
    "    input_ids      = enc.input_ids[win_i : win_i+1]\n",
    "    attention_mask = enc.attention_mask[win_i : win_i+1]\n",
    "    offsets        = enc.offset_mapping[win_i].tolist()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        start_logits = outputs.start_logits[0]\n",
    "        end_logits   = outputs.end_logits[0]\n",
    "\n",
    "    # Pick the highest start/end token (bruteforce)\n",
    "    s_idx = int(torch.argmax(start_logits).item())\n",
    "    e_idx = int(torch.argmax(end_logits).item())\n",
    "    score = (start_logits[s_idx] + end_logits[e_idx]).item()\n",
    "\n",
    "    # CLS token is always at position 0 in each window\n",
    "    cls_id = input_ids[0, 0].item()\n",
    "\n",
    "    # Print debug info for this window\n",
    "    print(f\"Window {win_i}:\")\n",
    "    print(f\"  CLS token id     = {cls_id}\")\n",
    "    print(f\"  Chosen start_idx = {s_idx}, end_idx = {e_idx}\")\n",
    "    print(f\"  Combined score   = {score:.4f}\")\n",
    "    print(f\"  Raw start_logits[:5] = {[round(x.item(),3) for x in start_logits[:5]]}\")\n",
    "    print(f\"  Raw   end_logits[:5] = {[round(x.item(),3) for x in end_logits[:5]]}\")\n",
    "    print(\"  Offsets[0:5]         =\", offsets[:5])\n",
    "    print(\"  Token IDs [0:5]      =\", input_ids[0].tolist()[:5], \"...\", input_ids[0].tolist()[-5:])\n",
    "    print(\"\")\n",
    "\n",
    "    # Track best span across all windows\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_span  = (win_i, s_idx, e_idx)\n",
    "\n",
    "# 7) Report the global best\n",
    "win_i, s_idx, e_idx = best_span\n",
    "char_start = enc.offset_mapping[win_i][s_idx][0]\n",
    "char_end   = enc.offset_mapping[win_i][e_idx][1]\n",
    "answer     = context[char_start:char_end]\n",
    "\n",
    "print(\"=== GLOBAL BEST SPAN ===\")\n",
    "print(f\"Window {win_i}, tokens [{s_idx}, {e_idx}], score {best_score:.4f}\")\n",
    "print(f\"Answer text: {repr(answer)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420ce67-299b-4c84-b875-e727310aafeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
