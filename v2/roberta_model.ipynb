{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4fdfce-b024-4fd9-a36d-04e0846b25c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c1f986885141168f357df43578fba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/286 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a135623d705f46d1b46763ec63d3654c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Train examples: 4121\n",
      "▶️ Val   examples: 1040\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Load & flatten SQuAD JSON\n",
    "raw = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"full\": \"f1_gp_qa.json\"},\n",
    "    field=\"data\"\n",
    ")[\"full\"]\n",
    "\n",
    "rows = []\n",
    "for item in raw:\n",
    "    for para in item[\"paragraphs\"]:\n",
    "        ctx = para[\"context\"]\n",
    "        for qa in para[\"qas\"]:\n",
    "            rows.append({\n",
    "                \"context\":     ctx,\n",
    "                \"question\":    qa[\"question\"],\n",
    "                \"answer_start\":qa[\"answers\"][0][\"answer_start\"],\n",
    "                \"answer_text\": qa[\"answers\"][0][\"text\"],\n",
    "            })\n",
    "\n",
    "flat_ds = Dataset.from_list(rows)\n",
    "\n",
    "# 2. Split into train/validation (80/20)\n",
    "split = flat_ds.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = split[\"train\"]\n",
    "val_ds   = split[\"test\"]\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# — 2) Define the robust prepare_features with fallback + clamp —\n",
    "def prepare_features(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"question\"],\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",      # only truncate the context\n",
    "        stride=128,                    # optional: use sliding windows\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    cls_id = tokenizer.cls_token_id\n",
    "    starts, ends = [], []\n",
    "\n",
    "    # iterate over each window\n",
    "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
    "        sample_idx  = tokenized[\"overflow_to_sample_mapping\"][i]\n",
    "        start_char  = examples[\"answer_start\"][sample_idx]\n",
    "        answer_text = examples[\"answer_text\"][sample_idx]\n",
    "        end_char    = start_char + len(answer_text)\n",
    "\n",
    "        # token window covers chars from offsets[0][0] to offsets[-1][1]\n",
    "        window_start, window_end = offsets[0][0], offsets[-1][1]\n",
    "\n",
    "        if not (window_start <= start_char < window_end):\n",
    "            # answer fell outside this window → point at CLS\n",
    "            raw_s = raw_e = tokenized[\"input_ids\"][i].index(cls_id)\n",
    "        else:\n",
    "            # find exact token span inside this window\n",
    "            raw_s = next(\n",
    "                idx for idx, (st, ed) in enumerate(offsets)\n",
    "                if st <= start_char < ed\n",
    "            )\n",
    "            raw_e = next(\n",
    "                idx for idx, (st, ed) in reversed(list(enumerate(offsets)))\n",
    "                if st < end_char <= ed\n",
    "            )\n",
    "\n",
    "        # clamp to [0, seq_len-1]\n",
    "        seq_len = len(offsets)\n",
    "        s = max(0, min(raw_s, seq_len - 1))\n",
    "        e = max(0, min(raw_e, seq_len - 1))\n",
    "\n",
    "        starts.append(s)\n",
    "        ends.append(e)\n",
    "\n",
    "    tokenized[\"start_positions\"] = starts\n",
    "    tokenized[\"end_positions\"]   = ends\n",
    "    tokenized.pop(\"offset_mapping\")\n",
    "    return tokenized\n",
    "\n",
    "# — 3) Apply to train & validation splits —\n",
    "train_tokenized = train_ds.map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=[\"context\", \"question\", \"answer_start\", \"answer_text\"]\n",
    ")\n",
    "val_tokenized = val_ds.map(\n",
    "    prepare_features,\n",
    "    batched=True,\n",
    "    remove_columns=[\"context\", \"question\", \"answer_start\", \"answer_text\"]\n",
    ")\n",
    "\n",
    "print(f\"▶️ Train examples: {len(train_tokenized)}\")\n",
    "print(f\"▶️ Val   examples: {len(val_tokenized)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98de9b5b-5610-47f6-a10c-997dc9aa4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1ff0d3-06df-4aaf-8140-f59316c0771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"roberta-base\"\n",
    "\n",
    "# 2) Load tokenizer & model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "740e43bd-832d-4cfe-8fa3-9d5c4786b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"./{model_name}_qa_model\",\n",
    "    overwrite_output_dir=True,\n",
    "\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    # Legacy strategy names to match older transformers versions:\n",
    "    eval_strategy=\"steps\",   # run validation every eval_steps\n",
    "    save_strategy=\"steps\",   # checkpoint every save_steps\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "\n",
    "    logging_steps=100,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-5,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=False,           # set True to force CPU\n",
    "    use_cpu=False            # set True to force CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011edcf5-35ce-4c6b-8172-d9ed0d040856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1537/3157013077.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2b50a1-c469-41b9-aad4-1ab154e788ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1548/1548 07:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1548, training_loss=0.040594189073809225, metrics={'train_runtime': 443.6308, 'train_samples_per_second': 27.868, 'train_steps_per_second': 3.489, 'total_flos': 2422808852645376.0, 'train_loss': 0.040594189073809225, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "421a26ad-9db6-4040-a6a9-9f56e3a5d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After trainer.train() completes:\n",
    "trainer.save_model(\"./qa_roberta_checkpoint\")\n",
    "# This saves both:\n",
    "#  - model weights → ./qa_model_checkpoint/pytorch_model.bin\n",
    "#  - config & tokenizer files → ./qa_model_checkpoint/config.json, tokenizer files…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270e13e-902c-4b40-9fb3-85c5b6854df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56dd71c5-a204-4792-bdab-5cecaa79628b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstart_logits\u001b[49m[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m5\u001b[39m], end_logits[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start_logits' is not defined"
     ]
    }
   ],
   "source": [
    "print(start_logits[0][:5], end_logits[0][:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8511a5-8121-43a8-8ed8-62bd4b874caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
